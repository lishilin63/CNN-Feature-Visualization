{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference List\n",
    "[1] Olah, et al., \"Feature Visualization\", Distill, 2017. Referenced from https://distill.pub/2017/feature-visualization/    \n",
    "[2] Kotikalapudi, et al., \"\n",
    "Keras Visualization Toolkit\", Keras-vis Documentation, 2018. Referenced from https://raghakot.github.io/keras-vis/vis.visualization/   \n",
    "[3] Qin, Z., Yu, F., Liu, C., & Chen, X., \"HOW CONVOLUTIONAL NEURAL NETWORKS SEE THE\n",
    "WORLD â€” A SURVEY OF CONVOLUTIONAL NEURAL  \n",
    "NETWORK VISUALIZATION METHODS\", Mathematical Foundations of Computing, 2018. Referenced from  [arXiv:1804.11191v2](https://arxiv.org/abs/1804.11191) [cs.CV]  \n",
    "[4] Nguyen, Y., Yosinski, J., & CluneReferenced, J.,\"Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks\", 2016, Referenced from [arXiv:1602.03616v2](https://arxiv.org/abs/1602.03616) [cs.NE]  \n",
    "[5] Chollet, F., \"How convolutional neural networks see the world\", Demo, 2016. Referenced from https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html   \n",
    "[6] Kotikalapudi, R.,\"What is Activation Maximization\", 2017, Referenced from https://raghakot.github.io/keras-vis/visualizations/activation_maximization/  \n",
    "[7] Kotikalapudi, R., \"Activation Maximization on MNIST\", 2017. Referenced from https://github.com/raghakot/keras-vis/blob/master/examples/mnist/activation_maximization.ipynb  \n",
    "[8] Kotikalapudi, R.,\"Activation Maximization on VGGNet\", 2017. Referenced from https://github.com/raghakot/keras-vis/blob/master/examples/vggnet/activation_maximization.ipynb  \n",
    "[9] Rajaraman, S., Silamut, K., Hossain, M.A., Ersoy, I., Maude, R.J., Jaeger, S., Thoma, G.R., Antani, S.K. \"Understanding the learned behavior of customized convolutional neural networks toward malaria parasite detection in thin blood smear images\", J Med Imaging (Bellingham), 2018 Jul;5(3):034501. doi: 10.1117/1.JMI.5.3.034501. Epub 2018 Jul 18. Referenced from https://lhncbc.nlm.nih.gov/publication/pub9809   \n",
    "[10] Kotikalapudi, R.,\"visualize_activation\", 2017. Referenced from https://raghakot.github.io/keras-vis/vis.visualization/#visualize_activation   \n",
    "[11] Chollet, F., \"Visualizing what convnets learn\",deep-learning-with-python-notebooks, 2017. Feferenced from https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb \n",
    "[12] Kaggle, \"Dogs vs. Cats\", 2013. Referenced from https://www.kaggle.com/c/dogs-vs-cats/data  \n",
    "[13] Chollet, F., \"Using convnets with small datasets\", 2017. Referened from https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.2-using-convnets-with-small-datasets.ipynb  \n",
    "[14] Kotikalapudi, R., \"Attention on ResNet50\", 2018. Referenced from https://github.com/raghakot/keras-vis/blob/master/examples/resnet/attention.ipynb  \n",
    "[15] Selvaraju, R.R., Das, A., Vedantam, R., Cogswell, M., Parikh, D., Batra, D., \"Grad-CAM: Why did you say that?\n",
    "Visual Explanations from Deep Networks via Gradient-based Localization\" 2017, Referenced from [arXiv:1610.02391v1](https://arxiv.org/abs/1610.02391v1) [cs.CV] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
