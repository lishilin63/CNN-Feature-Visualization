{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Visualization by Optimization\n",
    "** Fall 2018 GR5242 Final Project**   \n",
    "GR 001 MW 16:10-17:25  \n",
    "***Jiayi Dong (jd3416), Shilin Li (sl4261), Hengyang Lin(hl3116),  Wenting Zhu (wz2401)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Description **  \n",
    "We choose this project because neural networks as black box function approximators, most people are not sure how each layers are doing their jobs. Therefore, We want to explore what and how exactly different layers are extracting features. In this way, we will have a better understanding of different layers in CNN.\n",
    "\n",
    "The project has 3 parts. The 1st part we build a straightforward 2-layer CNN and train the model by using mnist dataset. We then visualize the input image which could activate a particular unit from the final dense layer. Then we build a more complicated CNN for training cats_dogs dataset. By controling parameters, we visualize the optimized input image that activate filters for each layer, and compare the result. Also, we used the well-known VGG16 model to visualize the optimized input image and compare each layers learning characterisitcs.  The 2nd part we are focusing on how a CNN learns a cat. Using the same model we have for cats_dogs dataset, we feed the network a cat picture and visualize what features the filter receives in each layer. This is another way we understand how CNN is doing classifications. The third part is an additional CNN extension of saliency maps, which are used to observe the important part of an imput picture that the CNN makes classification decision on. The model we use is ResNet50 with Grad-CAM method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our starting point **  \n",
    "When applying CNN in deep learning, people can generate the model by tuning parameters in each layer, but it is hard to interprete the function or ability of each layer by human beings. Inspired by the paper written by Olah, et al. in 2017 on [Distill](https://distill.pub/2017/feature-visualization/), we read more articles on Feature Visualization, especially on activation maximization as optimization method. Instead of simply visualize each layer, optimization fixes parameters' in trained model and try to generate the activation maximized input image to attain the best output. \n",
    "\n",
    "We first use the Mnist model to perform the feature visualization and then apply the same method to cat_dog_classification, which is a more complicated model but on a small scale of data, and finally move to VGG 16 model, which is a well-known trained model on a large scale of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The main challenge with the project**  \n",
    "The algorithm for the Activation Maximization that can apply to differnt CNN models is very complicated if we want to code from scratch. However, fortunately, a group of Google engineers develope [Keras-vis](https://raghakot.github.io/keras-vis/vis.visualization/) package, which can generalize Feature Visualization to all CNN models. We therefore focus on learning to utilize the Activation Maximization function and interprete different trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
